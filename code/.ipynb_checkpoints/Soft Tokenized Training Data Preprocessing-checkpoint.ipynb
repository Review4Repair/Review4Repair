{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessory functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def getJsonData(JsonFile):\n",
    "    with open(JsonFile, encoding=\"utf8\") as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keeps the datapoints that has less tokens than a particular threshold both in focus and target\n",
    "\n",
    "def limit_focus(data, limit):\n",
    "    data_new = []\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            focus_len = data[i]['soft_tokenized_code_snippet'].index('<|endfocus|>') \\\n",
    "            - data[i]['soft_tokenized_code_snippet'].index('<|startfocus|>')\n",
    "            target_len = len(data[i]['soft_tokenized_target'])\n",
    "        except:\n",
    "            focus_len = 300\n",
    "        if focus_len < limit and target_len < limit:\n",
    "            data_new.append(data[i])\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_dict(data, name):\n",
    "    with open(name, 'w', encoding=\"utf8\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Soft Detokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the soft tokenized code from the Hard tokenized code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVERSE_WHITESPACE_DICT = ['<|16-s|>', '<|12-s|>', '<|8-s|>', '<|4-s|>', '<|2-s|>', '<|s|>', '<|4-t|>', '<|3-t|>', '<|2-t|>', '<|t|>', '<|nl|>']\n",
    "\n",
    "def state(c):\n",
    "    n = ord(c)\n",
    "    if n>=97 and n<=122: # lower case\n",
    "        return 1\n",
    "    elif n>=65 and n<=90: # upper case\n",
    "        return 2\n",
    "    elif n>=48 and n<=57: # numbers\n",
    "        return 3\n",
    "    elif c.isspace(): # whitespaces\n",
    "        return 4\n",
    "    elif c in ['_', '$']: \n",
    "        return 5\n",
    "    elif n < 128:\n",
    "        return 6\n",
    "    else:\n",
    "        return 7\n",
    "\n",
    "def soft_detokenize(tokens):\n",
    "    new_tokens = ['#']\n",
    "    whitespace_on = 0\n",
    "    for i in range(len(tokens)):\n",
    "        token = tokens[i]\n",
    "        if state(token[0]) in [1,2,3,5] and state(new_tokens[-1][-1]) in [1,2,3,5] and not whitespace_on:\n",
    "            new_tokens[-1]+=token\n",
    "            whitespace_on = 0\n",
    "        elif token in REVERSE_WHITESPACE_DICT:\n",
    "            whitespace_on = 1\n",
    "            continue\n",
    "        else:\n",
    "            new_tokens.append(token)\n",
    "            whitespace_on = 0\n",
    "            \n",
    "    return new_tokens[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = getJsonData('jsons/train_soft.json')\n",
    "test = getJsonData('jsons/test_soft.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming Mild to Soft\n",
    "Renaming 'mild_tokenization' to 'soft_tokenization'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    train[i]['soft_tokenized_code_snippet'] = train[i]['mild_tokenized_code_snippet']\n",
    "    train[i]['soft_tokenized_comment'] = train[i]['mild_tokenized_comment']\n",
    "    train[i]['soft_tokenized_target'] = train[i]['mild_tokenized_target']\n",
    "    del train[i]['mild_tokenized_code_snippet']\n",
    "    del train[i]['mild_tokenized_comment']\n",
    "    del train[i]['mild_tokenized_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    test[i]['soft_tokenized_code_snippet'] = test[i]['mild_tokenized_code_snippet']\n",
    "    test[i]['soft_tokenized_comment'] = test[i]['mild_tokenized_comment']\n",
    "    test[i]['soft_tokenized_target'] = test[i]['mild_tokenized_target']\n",
    "    del test[i]['mild_tokenized_code_snippet']\n",
    "    del test[i]['mild_tokenized_comment']\n",
    "    del test[i]['mild_tokenized_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Soft Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    train[i]['soft_tokenized_code_snippet'] = soft_detokenize(train[i]['tokenized_code_snippet'])\n",
    "    train[i]['soft_tokenized_comment'] = soft_detokenize(train[i]['tokenized_comment'])\n",
    "    train[i]['soft_tokenized_target'] = soft_detokenize(train[i]['tokenized_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    test[i]['soft_tokenized_code_snippet'] = soft_detokenize(test[i]['tokenized_code_snippet'])\n",
    "    test[i]['soft_tokenized_comment'] = soft_detokenize(test[i]['tokenized_comment'])\n",
    "    test[i]['soft_tokenized_target'] = soft_detokenize(test[i]['tokenized_target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(train, \"jsons/train.json\")\n",
    "dump_dict(test, \"jsons/test.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit Focus and Target to 100 Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_100 = limit_focus(train, 100)\n",
    "test_100 = limit_focus(test, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(train_100, \"jsons/train_soft_100.json\")\n",
    "dump_dict(test_100, \"jsons/test_soft_100.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_100 = getJsonData('jsons/train_soft_100.json')\n",
    "test_100 = getJsonData('jsons/test_soft_100.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_freq = {}\n",
    "comment_freq = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train_100)):\n",
    "    source_tokens = train_100[i]['soft_tokenized_code_snippet']\n",
    "    target_tokens = train_100[i]['soft_tokenized_target']\n",
    "    comment_tokens = train_100[i]['soft_tokenized_comment']\n",
    "    code_tokens = source_tokens + target_tokens\n",
    "    \n",
    "    for x in code_tokens:\n",
    "        if x not in code_freq:\n",
    "            code_freq[x] = 0\n",
    "        code_freq[x] += 1\n",
    "        \n",
    "    for x in comment_tokens:\n",
    "        if x not in comment_freq:\n",
    "            comment_freq[x] = 0\n",
    "        comment_freq[x] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_code_freq = {k: v for k, v in sorted(code_freq.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_comment_freq = {k: v for k, v in sorted(comment_freq.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dump the file for future reference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(sorted_code_freq, 'jsons/sorted_code_freq_soft.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict(sorted_comment_freq, 'jsons/sorted_comment_freq_soft.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load from dumped data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_code_freq = getJsonData('jsons/sorted_code_freq_soft.json')\n",
    "sorted_comment_freq = getJsonData('jsons/sorted_comment_freq_soft.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Saving vocab text file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_out = open(\"vocab/target_vocab_soft_2000.txt\", \"w\", encoding='utf-8')\n",
    "source_out = open(\"vocab/source_vocab_soft_8000.txt\", \"w\", encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Take the first 'num_code_token' from the codes.\n",
    "\n",
    "num_code_token = 2000\n",
    "num_total_token = 10000\n",
    "\n",
    "for x in list(sorted_code_freq)[:num_code_token]:\n",
    "    target_out.write(x)\n",
    "    target_out.write(\"\\n\")\n",
    "target_out.close()\n",
    "\n",
    "src_vocab = list(sorted_code_freq)[:num_code_token]\n",
    "for tok in sorted_comment_freq:\n",
    "    if tok not in src_vocab and len(src_vocab) < num_total_token:\n",
    "        src_vocab.append(tok)\n",
    "\n",
    "for x in src_vocab:\n",
    "    source_out.write(x)\n",
    "    source_out.write(\"\\n\")\n",
    "source_out.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p training_data\n",
    "!mkdir -p training_data/c\n",
    "!mkdir -p training_data/cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getJsonData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5eec80999c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_100\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetJsonData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jsons/train_soft_100.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_100\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetJsonData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jsons/test_soft_100.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'getJsonData' is not defined"
     ]
    }
   ],
   "source": [
    "train_100 = getJsonData('jsons/train_soft_100.json')\n",
    "test_100 = getJsonData('jsons/test_soft_100.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code+Comment\n",
    "\n",
    "Write the train_100 file into OpenNMT training data. First CC, then C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_train = open(\"training_data/cc/soft-src-train.txt\", 'w')\n",
    "src_test = open(\"training_data/cc/soft-src-test.txt\", 'w')\n",
    "tgt_train = open(\"training_data/cc/soft-tgt-train.txt\", 'w')\n",
    "tgt_test = open(\"training_data/cc/soft-tgt-test.txt\", 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_100:\n",
    "    comment = '<|startcomment|> ' + ' '.join(x['soft_tokenized_comment'][:200]) + ' <|endcomment|> '\n",
    "    code_snippet = ' '.join(x['soft_tokenized_code_snippet']) + '\\n'\n",
    "    target = ' '.join(x['soft_tokenized_target']) + '\\n'\n",
    "    src_train.write(comment)\n",
    "    src_train.write(code_snippet)\n",
    "    tgt_train.write(target)\n",
    "src_train.close()\n",
    "tgt_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test_100:\n",
    "    comment = '<|startcomment|> ' + ' '.join(x['soft_tokenized_comment'][:200]) + ' <|endcomment|> '\n",
    "    code_snippet = ' '.join(x['soft_tokenized_code_snippet']) + '\\n'\n",
    "    target = ' '.join(x['soft_tokenized_target']) + '\\n'\n",
    "    src_test.write(comment)\n",
    "    src_test.write(code_snippet)\n",
    "    tgt_test.write(target)\n",
    "src_test.close()\n",
    "tgt_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset With Code only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_train = open(\"training_data/c/soft-src-train.txt\", 'w')\n",
    "src_test = open(\"training_data/c/soft-src-test.txt\", 'w')\n",
    "tgt_train = open(\"training_data/c/soft-tgt-train.txt\", 'w')\n",
    "tgt_test = open(\"training_data/c/soft-tgt-test.txt\", 'w') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in train_100:\n",
    "    #comment = '<|startcomment|> ' + ' '.join(x['soft_tokenized_comment'][:200]) + ' <|endcomment|> '\n",
    "    code_snippet = ' '.join(x['soft_tokenized_code_snippet']) + '\\n'\n",
    "    target = ' '.join(x['soft_tokenized_target']) + '\\n'\n",
    "    #src_train.write(comment)\n",
    "    src_train.write(code_snippet)\n",
    "    tgt_train.write(target)\n",
    "src_train.close()\n",
    "tgt_train.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in test_100:\n",
    "    #comment = '<|startcomment|> ' + ' '.join(x['soft_tokenized_comment'][:200]) + ' <|endcomment|> '\n",
    "    code_snippet = ' '.join(x['soft_tokenized_code_snippet']) + '\\n'\n",
    "    target = ' '.join(x['soft_tokenized_target']) + '\\n'\n",
    "    #src_test.write(comment)\n",
    "    src_test.write(code_snippet)\n",
    "    tgt_test.write(target)\n",
    "src_test.close()\n",
    "tgt_test.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Same Target and Focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2961"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['status', 'message', 'comment_id', 'target', 'code_snippet', 'prime_var_dic', 'class_list', 'func_list', 'tokenized_code_snippet', 'tokenized_target', 'tokenized_comment', 'global_index', 'base_code_line_number', 'base_patch_number', 'changed_patch_number', 'code_file_name', 'line_change', 'written_on', 'project_name', 'int_date', 'soft_tokenized_code_snippet', 'soft_tokenized_comment', 'soft_tokenized_target'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_100[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = test_100[0]['soft_tokenized_code_snippet'].index('<|startfocus|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = test_100[0]['soft_tokenized_code_snippet'].index('<|endfocus|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus = test_100[0]['soft_tokenized_code_snippet'][start+1:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = test_100[0]['soft_tokenized_target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "focus == target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Only keeps the datapoints that has less tokens than a particular threshold both in focus and target\n",
    "\n",
    "def remove_soft_unchanged(data):\n",
    "    data_new = []\n",
    "    for i in range(len(data)):\n",
    "        try:\n",
    "            start = test_100[i]['soft_tokenized_code_snippet'].index('<|startfocus|>')\n",
    "            end = test_100[i]['soft_tokenized_code_snippet'].index('<|endfocus|>')\n",
    "            focus = test_100[i]['soft_tokenized_code_snippet'][start+1:end]\n",
    "            target = test_100[i]['soft_tokenized_target']\n",
    "        except:\n",
    "            print(\"oops\")\n",
    "            focus = [1]\n",
    "            target = [2]\n",
    "            \n",
    "        if focus != target:\n",
    "            data_new.append(data[i])\n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_unchaged_removed_soft = remove_soft_unchanged(test_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2722"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_unchaged_removed_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "for x in test_unchaged_removed_soft:\n",
    "    s.append(x['global_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2381, 2384, 2385, 2386, 2387, 2388, 2389, 2390, 2391, 2489, 2562, 2575, 2576, 2577, 2620, 2621, 2640, 2617, 2618, 2619, 2643, 2644, 2645, 2648, 2342, 2343, 2393, 2653, 2654, 2655, 2656, 2657, 2658, 2659, 2660, 2662, 2664, 2665, 2666, 2668, 2688, 2689, 1482, 2582, 2583, 2635, 2087, 1484, 1520, 2683, 2684, 2685, 2686, 1531, 2486, 2487, 2767, 2773, 2774, 2775, 2776, 2777, 2778, 2781, 2785, 2786, 2787, 2788, 2789, 2790, 2791, 1496, 1522, 1523, 1524, 1525, 1527, 1528, 1529, 1530, 2670, 2671, 2672, 2673, 2757, 2759, 2760, 2761, 2762, 2763, 2779, 2780, 2783, 2784, 2807, 2808, 2817, 1546, 2623, 2692, 2693, 2694, 2805, 2806, 2818, 2819, 2820, 2821, 2822, 2824, 2825, 2826, 2827, 2044, 2584, 2691, 2772, 2803, 2811, 2814, 2830, 2834, 2870, 2872, 2465, 2473, 2474, 2475, 2476, 2513, 2604, 2770, 2836, 2869, 2464, 2471, 2524, 1539, 2843, 2844, 2845, 2846, 2847, 2848, 2849, 2850, 2851, 2852, 2853, 2854, 2855, 2856, 2857, 2858, 2859, 2860, 2861, 2873, 2875, 1498, 1499, 1502, 1503, 1504, 1514, 1515, 1516, 2482, 1576, 1577, 2798, 2799, 2842, 2877, 2878, 2879, 2880, 2901, 2904, 2331, 2479, 1541, 1542, 1543, 1544, 1545, 2829, 2894, 2896, 2898, 2899, 2905, 2906, 1574, 1575, 2517, 2518, 2525, 2625, 2626, 2907, 2912, 2918, 2610, 2611, 2837, 2841, 2911, 2914, 2915, 2916, 2919, 2928, 2587, 2588, 2589, 2590, 2591, 1540, 1564, 2594, 2595, 2596, 2597, 2833, 2881, 2883, 2884, 2885, 2886, 2887, 2917, 2930, 2948, 2949, 2523, 2609, 2631, 2632, 2888, 2933, 2934, 2935, 2936, 2937, 2939, 2940, 2941, 2946, 1586, 1587, 1588, 1591, 1592, 1593, 1594, 1595, 1596, 2598, 2599, 2600, 2734, 2735, 2736, 2737, 2738, 2739, 2740, 2741, 2742, 2943, 2945, 2950, 2298, 2299, 2300, 2301, 1590, 1609, 2815, 2816, 2892, 2931, 2960, 2961, 2962, 2963, 1537, 1584, 1585, 1612, 1613, 1615, 1616, 1628, 2586, 2695, 2697, 2698, 2701, 2702, 2703, 2706, 2707, 2710, 2711, 2712, 2713, 2716, 2717, 2718, 2719, 2720, 2721, 2722, 2723, 2947, 2969, 2972, 2973, 2974, 2978, 2980, 2982, 2983, 2984, 2985, 2696, 2966, 2968, 2991, 1579, 1580, 1581, 1582, 1583, 1629, 2990, 2992, 2979, 2986, 2987, 2988, 2989, 1562, 1566, 1571, 1572, 1573, 1597, 1598, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1614, 1634, 1635, 1636, 1637, 1645, 1646, 2994, 1618, 1500, 1554, 1556, 1631, 1632, 1667, 1668, 1694, 1695, 1497, 1547, 1548, 1549, 1550, 1551, 1638, 1661, 1704, 1641, 1663, 1664, 1677, 1701, 1702, 1709, 1718, 1719, 1651, 1652, 1703, 1711, 1712, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1731, 1737, 1750, 1751, 1647, 1662, 1665, 1666, 1741, 1611, 1625, 1736, 1743, 1766, 1770, 1779, 1780, 1781, 1782, 1783, 1784, 1792, 1794, 1653, 1654, 1732, 1787, 1788, 1789, 1790, 1793, 1795, 1796, 1803, 1610, 1627, 1753, 1754, 1760, 1762, 1763, 1764, 1765, 1773, 1774, 1775, 1776, 1777, 1778, 1785, 1807, 1808, 1809, 1810, 1811, 1644, 1669, 1671, 1672, 1812, 1814, 1805, 1806, 1816, 1817, 1820, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1533, 1798, 1799, 1800, 1801, 1821, 1823, 1824, 1825, 1826, 1827, 1829, 1834, 1839, 1840, 1843, 1706, 1707, 1739, 1832, 1835, 1841, 1847, 1848, 1849, 1850, 1854, 1855, 1856, 1857, 1858, 1859, 1862, 1532, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1822, 1842, 1863, 1864, 1865, 1866, 1867, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1884, 1831, 1885, 1898, 1887, 1888, 1889, 1891, 1893, 1894, 1896, 1897, 1928, 1929, 1930, 1947, 1909, 1939, 1918, 1943, 1951, 1952, 1953, 1954, 1955, 1916, 1917, 1899, 1900, 1935, 1938, 1950, 1956, 1957, 1678, 1679, 1681, 1682, 1926, 1958, 1959, 1431, 1432, 1508, 1964, 1968, 1974, 1975, 1976, 1981, 1969, 1970, 1971, 1972, 1986, 1988, 1989, 1977, 1978, 1979, 1980, 1983, 1991, 1993, 1994, 2002, 1982, 2000, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2012, 1996, 1997, 1998, 2013, 1995, 1325, 1326, 1327, 1328, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1297, 1298, 1312, 1313, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1348, 1349, 1350, 1359, 1360, 1362, 1363, 1367, 1368, 1369, 1370, 1371, 1373, 1374, 1377, 1379, 1380, 1381, 1382, 1386, 44080, 44082, 44083, 44084, 44085, 44086, 44108, 44110, 44239, 44240, 43904, 43933, 43684, 43851, 44237, 44321, 44326, 44327, 39559, 44316, 44317, 44318, 44319, 39407, 39408, 39409, 39410, 39411, 39412, 39413, 39414, 39415, 39416, 39417, 39418, 39419, 39420, 39423, 39426, 39428, 39429, 39430, 39513, 39514, 39518, 43792, 44305, 43835, 39355, 39358, 39359, 39363, 39365, 39366, 39367, 39406, 44302, 44303, 39346, 39350, 39351, 44335, 44336, 44337, 44338, 44101, 44339, 44340, 44341, 44343, 44344, 44345, 44346, 44348, 44351, 44352, 44358, 44359, 44364, 44366, 44363, 44367, 43831, 44371, 44372, 44388, 44390, 44391, 44393, 44394, 44353, 44354, 44355, 44356, 44357, 44400, 44402, 44404, 44405, 44406, 44407, 44408, 44409, 44410, 44411, 44412, 44413, 44414, 44415, 44416, 44417, 44418, 44419, 44420, 44421, 44422, 44423, 44424, 44425, 44426, 44427, 44428, 44429, 44430, 44431, 44432, 44433, 44434, 44435, 44436, 44437, 44569, 44575, 44577, 44660, 44661, 44666, 44681, 44682, 44690, 44691, 44694, 44695, 44696, 44697, 44702, 44703, 44709, 44710, 44712, 44713, 44716, 44572, 44573, 44579, 44580, 44583, 44720, 44297, 44389, 44640, 44641, 44642, 39748, 39749, 39750, 39751, 39752, 44286, 44287, 44288, 44289, 44755, 44757, 39728, 39729, 42091, 42094, 42099, 39715, 39716, 44636, 44637, 44730, 44731, 44732, 44734, 44735, 44736, 44738, 44741, 44742, 44630, 44761, 44762, 44766, 44624, 39683, 39684, 39685, 39687, 39688, 39689, 44772, 44768, 44770, 44606, 44607, 44609, 44610, 44613, 44614, 44616, 44619, 44622, 44597, 44598, 44603, 44605, 44608, 44615, 44620, 44774, 44587, 44588, 44589, 44590, 44591, 44592, 42407, 42409, 42410, 44799, 44800, 44801, 44802, 44088, 44816, 44817, 39911, 39912, 43973, 44820, 44821, 41636, 44808, 44822, 44823, 44824, 44825, 44826, 44827, 44828, 44829, 44830, 44831, 44832, 44833, 44834, 44835, 44836, 44837, 44838, 44839, 44840, 44841, 44842, 44843, 44844, 44845, 44846, 44847, 44848, 44849, 44850, 44851, 44852, 44853, 44854, 44855, 44856, 44857, 44858, 44859, 44860, 44861, 44862, 44863, 44864, 44865, 44866, 44867, 44868, 44869, 44870, 44871, 44872, 44873, 44874, 44875, 44876, 44877, 44878, 44879, 44880, 44881, 44882, 44883, 44884, 44885, 44886, 44887, 44888, 44889, 44890, 44891, 44892, 44893, 44894, 44895, 44896, 44910, 44911, 44912, 44914, 44909, 44913, 44915, 44916, 44917, 44918, 44920, 44921, 44922, 44923, 44924, 44927, 44931, 44936, 44939, 44944, 44945, 44948, 44943, 44949, 44950, 42406, 42415, 44954, 44955, 44956, 44971, 44973, 39383, 44899, 44901, 44897, 44898, 44979, 44986, 44989, 44990, 44975, 44976, 44997, 44998, 45000, 45002, 45003, 45005, 45007, 45017, 45023, 45024, 45025, 44270, 44271, 44275, 44276, 44277, 44278, 44279, 44280, 44281, 44995, 44996, 45001, 45004, 45006, 45020, 45026, 44258, 44262, 44264, 44265, 44268, 44269, 44252, 44253, 44254, 44255, 44256, 44257, 45029, 45032, 45033, 45034, 45042, 45047, 45049, 45050, 45051, 45046, 44992, 45055, 45056, 30409, 30412, 53326, 53000, 53001, 53149, 53185, 53186, 52690, 52998, 52999, 53144, 53145, 53146, 53147, 53148, 53165, 53166, 53167, 53169, 53170, 53171, 53172, 53173, 53174, 53175, 53176, 53177, 53178, 53179, 53180, 53181, 53182, 53183, 53184, 53196, 53197, 53201, 53202, 53203, 53204, 53205, 53206, 53207, 53209, 53211, 53212, 52682, 53141, 53164, 53220, 53221, 53222, 53223, 53224, 53225, 53228, 53229, 53230, 53231, 53139, 53140, 53217, 53218, 53341, 53369, 53372, 53379, 53380, 53367, 53375, 53376, 53381, 53233, 53237, 53318, 53319, 53350, 53351, 53396, 53357, 53358, 53359, 53362, 52689, 53364, 53398, 53405, 53406, 53407, 53408, 53409, 53416, 53423, 53424, 53425, 53446, 53400, 53401, 53402, 53403, 53404, 53456, 53457, 53460, 53462, 53463, 53464, 53465, 53466, 53468, 53495, 53522, 53344, 53511, 53512, 53524, 53557, 53474, 53535, 53599, 53698, 53523, 53569, 53573, 53574, 53540, 53541, 53542, 53543, 53546, 53547, 53548, 53549, 53550, 53553, 53555, 53556, 53563, 53565, 53566, 53539, 53626, 53634, 53644, 53645, 53505, 53663, 53671, 53672, 53673, 53674, 53675, 53677, 53676, 53693, 53694, 53697, 54094, 54082, 54085, 54086, 54087, 54089, 54091, 54097, 54099, 54095, 54096, 54100, 54101, 54102, 54103, 54104, 54105, 54109, 54121, 54122, 54123, 54124, 54125, 54131, 54132, 54133, 54134, 54120, 54139, 54135, 54143, 54144, 54142, 54149, 54138, 54140, 54146, 54147, 54148, 54145, 54150, 54151, 54152, 54153, 54154, 71228, 71229, 71230, 71233, 71071, 71231, 71232, 71167, 71168, 71169, 71170, 71171, 71172, 71173, 71174, 71175, 71201, 71202, 71203, 71204, 71205, 71257, 71256, 63880, 63881, 63882, 63885, 63886, 70339, 71267, 70989, 71247, 71249, 71250, 71251, 71252, 71253, 71254, 71272, 71273, 71245, 71260, 71262, 71263, 71264, 71265, 71236, 71237, 71238, 71240, 71235, 71239, 71258, 71276, 70189, 71277, 71282, 71283, 71284, 71291, 71274, 71268, 71269, 71270, 71271, 71278, 71279, 71280, 71309, 71310, 71311, 71314, 71315, 71316, 71317, 71318, 71319, 71321, 71322, 71176, 71292, 71293, 71294, 71295, 71296, 71297, 71298, 71299, 71300, 71301, 71302, 71303, 71304, 71305, 71307, 71320, 71328, 71329, 71330, 71331, 71356, 71357, 71358, 71359, 71361, 71364, 71365, 71367, 71308, 71334, 71368, 71098, 71332, 71333, 71335, 71336, 71337, 71370, 71338, 71340, 71341, 71342, 71343, 71344, 71345, 71346, 71347, 71349, 71350, 71351, 71352, 71353, 71354, 71355, 71373, 71150, 71151, 71152, 71153, 71371, 71324, 71372, 71375, 71376, 71377, 71378, 71379, 71380, 71381, 71383, 71384, 71385, 71386, 71387, 71388, 71389, 71390, 71391, 71392, 71393, 71395, 71397, 71399, 71400, 71401, 70249, 71402, 71403, 71406, 71404, 71414, 71416, 71466, 71415, 71437, 71438, 71468, 71469, 71471, 71431, 71409, 71410, 71411, 71412, 71413, 71421, 71423, 71424, 71425, 71480, 71481, 71484, 71485, 71493, 71494, 71492, 71427, 71428, 71429, 71486, 71491, 71426, 71473, 71474, 71475, 71487, 71488, 71489, 71490, 71521, 71529, 71530, 71496, 71498, 71515, 71537, 71476, 71477, 71478, 71513, 71514, 71524, 71525, 71526, 71527, 71533, 71538, 71539, 71540, 71452, 71454, 71457, 71459, 71460, 71461, 71462, 71618, 71620, 71625, 71528, 71523, 71417, 71418, 71633, 71634, 71635, 71467, 71499, 71500, 71502, 71505, 71651, 71652, 71653, 71654, 71655, 71656, 71658, 71662, 71664, 71560, 71659, 71660, 71661, 71663, 71665, 71666, 71667, 71546, 71547, 71548, 71549, 71668, 71637, 71638, 71639, 71640, 71561, 71562, 71563, 71564, 71565, 71566, 71669, 71670, 71671, 71672, 71673, 71519, 71520, 71597, 71598, 71600, 71510, 71583, 71584, 71585, 71586, 71587, 71589, 71590, 71591, 71592, 71593, 71615, 71616, 71439, 71440, 71441, 71442, 71443, 71444, 71445, 71446, 71447, 71448, 71449, 71450, 71603, 71604, 71605, 71606, 71607, 71608, 71609, 71611, 71613, 71614, 63849, 70245, 71281, 71369, 71567, 71568, 71569, 71570, 71571, 71572, 71573, 71574, 71575, 71576, 71577, 71578, 71579, 71580, 71581, 71692, 71681, 71682, 70276, 70277, 70278, 70280, 70281, 70284, 70286, 70287, 70288, 70289, 70290, 70291, 70292, 70293, 70294, 70295, 70296, 71512, 71716, 71717, 71718, 71722, 71724, 70240, 70242, 70243, 71285, 71286, 71287, 71288, 71289, 71727, 71511, 71731, 71541, 70799, 71691, 71737, 71679, 71465, 71714, 71715, 71741, 71742, 71743, 71745, 71746, 71747, 70797, 70798, 71735, 71739, 71748, 71542, 71543, 71544, 71757, 71758, 71759, 71755, 71760, 71761, 71767, 71763, 71787, 71799, 71800, 71801, 71802, 71803, 71804, 70233, 70234, 70235, 70236, 70239, 70262, 70264, 70265, 70266, 70267, 70270, 70271, 70272, 70273, 70274, 70275, 70256, 70257, 70261, 71806, 71807, 71822, 70254, 70255, 71788, 71789, 71797, 71798, 70305, 71811, 71812, 71813, 71814, 71815, 71816, 71817, 71818, 71819, 71823, 71824, 71775, 71776, 71777, 71779, 71780, 71781, 71782, 71783, 71784, 71785, 71786, 70346, 70347, 70349, 71826, 71828, 71829, 70348, 71831, 71832, 71833, 71834, 71835, 71796, 71792, 71793, 63826, 71846, 71848, 71847, 71851, 71852, 71853, 63799, 71857, 63798, 71855, 71861, 71862, 71863, 71864, 71841, 71842, 71843, 71844, 71860, 71865, 71868, 71876, 71881, 71886, 71887, 71866, 71867, 71890, 71891, 71892, 63889, 63890, 63891, 63892, 71893, 71894, 71895, 71885, 71904, 71905, 71900, 71901, 71902, 71906, 71907, 71908, 71909, 71910, 71911, 71912, 71913, 71914, 71919, 71920, 71923, 71924, 71925, 71932, 71939, 71945, 71942, 71944, 71946, 71947, 71948, 71952, 71928, 71929, 71930, 71953, 71954, 71955, 71956, 71957, 71958, 71950, 71951, 71960, 71961, 72809, 72810, 72811, 72812, 72813, 72741, 72742, 72743, 72747, 72750, 72755, 72756, 72757, 72758, 72739, 72740, 72815, 72816, 72817, 72818, 72819, 72820, 72822, 72823, 72824, 72825, 72826, 72827, 72860, 72861, 72862, 72863, 72866, 72867, 72868, 72869, 72870, 72871, 72872, 72873, 72874, 72875, 72876, 72879, 72878, 72881, 72886, 72887, 72889, 72890, 72891, 72892, 72893, 72898, 72901, 72903, 72906, 72908, 72909, 72910, 72911, 72912, 72913, 72914, 72930, 72915, 72916, 72917, 72920, 72921, 72922, 72923, 72924, 72927, 72928, 72929, 72931, 72933, 72936, 72937, 72938, 72829, 72830, 72828, 76755, 76756, 76769, 76770, 76783, 76784, 76785, 76790, 76793, 76794, 76796, 76303, 76786, 76787, 76798, 76799, 76800, 76801, 76802, 75990, 76821, 76822, 76823, 76824, 76825, 76826, 76827, 76828, 76829, 76830, 76831, 76832, 76833, 76841, 76842, 76843, 76844, 76807, 76820, 76835, 76836, 76837, 76838, 76839, 76840, 76852, 76853, 76854, 76806, 76819, 76847, 76848, 76849, 76855, 76856, 76857, 76858, 76859, 75997, 76726, 76727, 76728, 76729, 76730, 76731, 76732, 76791, 76792, 76850, 76851, 76860, 76861, 76683, 76684, 76685, 76686, 76689, 76690, 76691, 76692, 76693, 76733, 76863, 76865, 76866, 76868, 76869, 76870, 76871, 76872, 76873, 76874, 76875, 76878, 76880, 76881, 76882, 76884, 76892, 76898, 76899, 76900, 76901, 76902, 76734, 76735, 76736, 76737, 76808, 76694, 76695, 76809, 76812, 76814, 76815, 76885, 76888, 76889, 76890, 76891, 76916, 76931, 76910, 76911, 76886, 76887, 76905, 76906, 76907, 76908, 76909, 76950, 76920, 76922, 76917, 76936, 76937, 76951, 76952, 76953, 76954, 76967, 76968, 76913, 76915, 76939, 76973, 76961, 76963, 76965, 76966, 76969, 76975, 76941, 76942, 76943, 76986, 76978, 76981, 77000, 77001, 77002, 76985, 76998, 76999, 77008, 76996, 77004, 77005, 77006, 77009, 77011, 77012, 77028, 77029, 77030, 77031, 77032, 77033, 77034, 77035, 77036, 77018, 76971, 77037, 77019, 77020, 77022, 77023, 77025, 77026, 77045, 77007, 77013, 77014, 77056, 77057, 77059, 77060, 77016, 77063, 77064, 77065, 77066, 77067, 77068, 77069, 77070, 76944, 76945, 76946, 77071, 77072, 77073, 77074, 77046, 77047, 77052, 77053, 77054, 77149, 77150, 77151, 77152, 76361, 77170, 77171, 77172, 77173, 77076, 77078, 77079, 77080, 77083, 77084, 77085, 77086, 77090, 77096, 77098, 77099, 77100, 77102, 77174, 77187, 77191, 77192, 77193, 77194, 77195, 77196, 77197, 77198, 77199, 77201, 77202, 77205, 77040, 77041, 77154, 77163, 77164, 77168, 77186, 77188, 77189, 77190, 77207, 77213, 76955, 76956, 76957, 76958, 76959, 76960, 77209, 77211, 77212, 77220, 76987, 76988, 76989, 76993, 77215, 77216, 77217, 77218, 77219, 77222, 77224, 77226, 77227, 77228, 77118, 77119, 77120, 77121, 77122, 77123, 77124, 77127, 77128, 77129, 77130, 77131, 77132, 77133, 77125, 77126, 77135, 77136, 77137, 77138, 77144, 77145, 77146, 77232, 77233, 77237, 77238, 77234, 77214, 77239, 76976, 76977, 76982, 77229, 77244, 77252, 77254, 76992, 77248, 77255, 77256, 77257, 77258, 77245, 77246, 77247, 77249, 77259, 77265, 77266, 77273, 77274, 77175, 77176, 77177, 77178, 77179, 77180, 77181, 77182, 77183, 77184, 77185, 77240, 77241, 77242, 77253, 77260, 77261, 77263, 77272, 77277, 77278, 77279, 77284, 77301, 77305, 77306, 77312, 77313, 77324, 77325, 77326, 77262, 77295, 77296, 77308, 77327, 77334, 77264, 77297, 77298, 77299, 77342, 77343, 77344, 77347, 77348, 77349, 77352, 77353, 77354, 77355, 77356, 77357, 77281, 77337, 77359, 77360, 77361, 77364, 77398, 77371, 77372, 77374, 77375, 77376, 77377, 77381, 77382, 77399, 77366, 77367, 77401, 77402, 77403, 77408, 77410, 77407, 77406, 77368, 77392, 77394, 77395, 77396, 77397, 77412, 77413, 77414, 77383, 77384, 77386, 77387, 77389, 77390, 77267, 77268, 77269, 77270, 77271, 77420, 77421, 77422, 77423, 77435, 77436, 77425, 77426, 77427, 77437, 77440, 77411, 77442, 77369, 77429, 77456, 77443, 77446, 77462, 77463, 77464, 77465, 77448, 77449, 77450, 77451, 77452, 77453, 77459, 77460, 77461, 77454, 77455, 77467, 77468, 77470, 77340, 77341, 77474, 77475, 77489, 77501, 77499, 77500, 77505, 77488, 77498, 77507, 77508, 77509, 77510, 77512, 77513, 77514, 77515, 77516, 77517, 77528, 77533, 77477, 77529, 77530, 77534, 77520, 77535, 77536, 77538, 77543, 77565, 77566, 77570, 77571, 77481, 77482, 77556, 77557, 77573, 77574, 77490, 77491, 77579, 77581, 77610, 77612, 77613, 77614, 77317, 77618, 77619, 77469, 77518, 77519, 77569, 77616, 77617, 77647, 77648, 77666, 77667, 77668, 77686, 77531, 77532, 77592, 77593, 77685, 77687, 77692, 77693, 77694, 77696, 77697, 77688, 77689, 77698, 77699, 77700, 77577, 77578, 77631, 77632, 77634, 77636, 77637, 77638, 77639, 77640, 77701, 77702, 77704, 77705, 77716, 77582, 77583, 77584, 77586, 77587, 77589, 77690, 77691, 77633, 77729, 77730, 77732, 77650, 77720, 77731, 77734, 77735, 77742, 77743, 77744, 77745, 77749, 77750, 77751, 77649, 77706, 77721, 77722, 77724, 77752, 77753, 77641, 77642, 77644, 77645, 77646, 77707, 77717, 77746, 77754, 77758, 77748, 77759, 77622, 77521, 77522, 77523, 77524, 77725, 77726, 77727, 77728, 77760, 77761, 77591, 77709, 77710, 77711, 77712, 77713, 77714, 77715, 77767, 77771, 77594, 77597, 77598, 77599, 77768, 77769, 77770, 77774, 77775, 77756, 77772, 77773, 77776, 77764, 77765, 77766, 77777, 77780, 77781, 77782, 77783, 77784, 77785, 77786, 77787, 77789, 77790, 77492, 77493, 77494, 77495, 77496, 77497, 77684, 77792, 77627, 77628, 77629, 77788, 77806, 77807, 77810, 77808, 77813, 77669, 77670, 77671, 77672, 77673, 77674, 77675, 77679, 77680, 77681, 77682, 77657, 77658, 77659, 77661, 77662, 77663, 77664, 77665, 77678, 77796, 77811, 77816, 77817, 77818, 77819, 77652, 77653, 77654, 77655, 77656, 77815, 77821, 77812, 77824, 77825, 99964, 99965, 99966, 99972, 99973, 99951, 99952, 99977, 99978, 99980, 99981, 99982, 99984, 99987, 99986, 100032, 100028, 100030, 99997, 100009, 100000, 100001, 100005, 100022, 100010, 100042, 100040, 100048, 100049, 100050, 100051, 100052, 100053, 100054, 100055, 100056, 100057, 100058, 100059, 45082, 100303, 100304, 100307, 100315, 100312, 100317, 100318, 100319, 100320, 100324, 100325, 100323, 55076, 100508, 100509, 100511, 100792, 100814, 100816, 100817, 100818, 100819, 100805, 100808, 100811, 100812]\n"
     ]
    }
   ],
   "source": [
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
