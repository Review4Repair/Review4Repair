{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-19 08:23:54,107 INFO] Extracting features...\n",
      "[2020-03-19 08:23:54,173 INFO]  * number of source features: 0.\n",
      "[2020-03-19 08:23:54,173 INFO]  * number of target features: 0.\n",
      "[2020-03-19 08:23:54,173 INFO] Building `Fields` object...\n",
      "[2020-03-19 08:23:54,173 INFO] Building & saving training data...\n",
      "[2020-03-19 08:23:54,173 INFO] Using existing vocabulary...\n",
      "[2020-03-19 08:23:54,173 INFO] Building vocab from text file...\n",
      "[2020-03-19 08:23:54,173 INFO] Loading src vocabulary from vocab/cc/source_vocab_cc_10000.txt\n",
      "[2020-03-19 08:23:54,195 INFO] Loaded src vocab has 10000 tokens.\n",
      "[2020-03-19 08:23:54,199 INFO] Loading tgt vocabulary from vocab/cc/target_vocab_cc_2000.txt\n",
      "[2020-03-19 08:23:54,204 INFO] Loaded tgt vocab has 2000 tokens.\n",
      "[2020-03-19 08:26:35,310 INFO] Building shard 0.\n",
      "[2020-03-19 08:30:39,431 INFO]  * saving 0th train data shard to data/cc/pretrain_data.train.0.pt.\n",
      "[2020-03-19 08:38:47,944 INFO]  * tgt vocab size: 2004.\n",
      "[2020-03-19 08:38:47,960 INFO]  * src vocab size: 10002.\n"
     ]
    }
   ],
   "source": [
    "!onmt_preprocess -train_src raw_data/cc/pretrain-src-train.txt \\\n",
    "    -train_tgt raw_data/cc/pretrain-tgt-train.txt \\\n",
    "    -save_data data/cc/pretrain_data \\\n",
    "    -src_vocab vocab/cc/source_vocab_cc_10000.txt \\\n",
    "    -tgt_vocab vocab/cc/target_vocab_cc_2000.txt \\\n",
    "    -src_vocab_size 10000 \\\n",
    "    -tgt_vocab_size 2000 \\\n",
    "    -src_seq_length 400 \\\n",
    "    -src_seq_length_trunc 400 \\\n",
    "    -tgt_seq_length 200 \\\n",
    "    -tgt_seq_length_trunc 200 \\\n",
    "    -dynamic_dict \\\n",
    "    -overwrite\n",
    "\n",
    "#-valid_src raw_data/cc/mild-src-test.txt \\\n",
    "#    -valid_tgt raw_data/cc/mild-tgt-test.txt \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-19 08:43:24,014 INFO]  * src vocab size = 10002\n",
      "[2020-03-19 08:43:24,014 INFO]  * tgt vocab size = 2004\n",
      "[2020-03-19 08:43:24,014 INFO] Building model...\n",
      "[2020-03-19 08:43:26,032 INFO] NMTModel(\n",
      "  (encoder): RNNEncoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(10002, 128, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (rnn): LSTM(128, 256, bidirectional=True)\n",
      "    (bridge): ModuleList(\n",
      "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "      (1): Linear(in_features=256, out_features=256, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (decoder): InputFeedRNNDecoder(\n",
      "    (embeddings): Embeddings(\n",
      "      (make_embedding): Sequential(\n",
      "        (emb_luts): Elementwise(\n",
      "          (0): Embedding(2004, 128, padding_idx=1)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (rnn): StackedLSTM(\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (layers): ModuleList(\n",
      "        (0): LSTMCell(640, 512)\n",
      "      )\n",
      "    )\n",
      "    (attn): GlobalAttention(\n",
      "      (linear_context): Linear(in_features=512, out_features=512, bias=False)\n",
      "      (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
      "      (v): Linear(in_features=512, out_features=1, bias=False)\n",
      "      (linear_out): Linear(in_features=1024, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (generator): CopyGenerator(\n",
      "    (linear): Linear(in_features=512, out_features=2004, bias=True)\n",
      "    (linear_copy): Linear(in_features=512, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "[2020-03-19 08:43:26,032 INFO] encoder: 2202368\n",
      "[2020-03-19 08:43:26,032 INFO] decoder: 4698581\n",
      "[2020-03-19 08:43:26,032 INFO] * number of parameters: 6900949\n",
      "[2020-03-19 08:43:26,035 INFO] Starting training on GPU: [0]\n",
      "[2020-03-19 08:43:26,035 INFO] Start training loop without validation...\n",
      "[2020-03-19 08:43:26,035 INFO] Loading dataset from data/cc/pretrain_data.train.0.pt\n",
      "[2020-03-19 08:45:51,988 INFO] number of examples: 677957\n",
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/torchtext/data/field.py:359: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  var = torch.tensor(arr, dtype=self.dtype, device=device)\n",
      "[2020-03-19 08:47:40,820 INFO] Step 100/500000; acc:  16.08; ppl: 65.40; xent: 4.18; lr: 0.15000; 6513/600 tok/s;    255 sec\n",
      "[2020-03-19 08:49:27,473 INFO] Step 200/500000; acc:  20.85; ppl: 49.39; xent: 3.90; lr: 0.15000; 15570/1530 tok/s;    361 sec\n",
      "[2020-03-19 08:51:13,523 INFO] Step 300/500000; acc:  20.50; ppl: 47.35; xent: 3.86; lr: 0.15000; 15959/1539 tok/s;    467 sec\n",
      "[2020-03-19 08:53:03,842 INFO] Step 400/500000; acc:  22.11; ppl: 37.01; xent: 3.61; lr: 0.15000; 14796/1545 tok/s;    578 sec\n",
      "[2020-03-19 08:54:47,127 INFO] Step 500/500000; acc:  23.91; ppl: 33.12; xent: 3.50; lr: 0.15000; 16214/1453 tok/s;    681 sec\n",
      "[2020-03-19 08:56:35,083 INFO] Step 600/500000; acc:  24.47; ppl: 31.74; xent: 3.46; lr: 0.15000; 15115/1546 tok/s;    789 sec\n",
      "[2020-03-19 08:58:31,267 INFO] Step 700/500000; acc:  26.21; ppl: 25.67; xent: 3.25; lr: 0.15000; 14475/1484 tok/s;    905 sec\n",
      "[2020-03-19 09:00:12,735 INFO] Step 800/500000; acc:  29.93; ppl: 20.96; xent: 3.04; lr: 0.15000; 16081/1478 tok/s;   1007 sec\n",
      "[2020-03-19 09:00:12,946 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_800.pt\n",
      "[2020-03-19 09:02:00,886 INFO] Step 900/500000; acc:  33.26; ppl: 18.40; xent: 2.91; lr: 0.15000; 15618/1549 tok/s;   1115 sec\n",
      "[2020-03-19 09:03:52,297 INFO] Step 1000/500000; acc:  36.72; ppl: 16.67; xent: 2.81; lr: 0.15000; 14621/1611 tok/s;   1226 sec\n",
      "[2020-03-19 09:05:47,723 INFO] Step 1100/500000; acc:  39.61; ppl: 14.66; xent: 2.68; lr: 0.15000; 14863/1374 tok/s;   1342 sec\n",
      "[2020-03-19 09:07:41,206 INFO] Step 1200/500000; acc:  38.92; ppl: 15.50; xent: 2.74; lr: 0.15000; 14582/1654 tok/s;   1455 sec\n",
      "[2020-03-19 09:09:27,991 INFO] Step 1300/500000; acc:  44.28; ppl: 12.18; xent: 2.50; lr: 0.15000; 15387/1539 tok/s;   1562 sec\n",
      "[2020-03-19 09:11:18,425 INFO] Step 1400/500000; acc:  47.66; ppl: 10.94; xent: 2.39; lr: 0.15000; 15123/1576 tok/s;   1672 sec\n",
      "[2020-03-19 09:12:56,482 INFO] Step 1500/500000; acc:  51.73; ppl:  8.92; xent: 2.19; lr: 0.15000; 16644/1396 tok/s;   1770 sec\n",
      "[2020-03-19 09:14:48,424 INFO] Step 1600/500000; acc:  54.23; ppl:  8.29; xent: 2.11; lr: 0.15000; 15188/1550 tok/s;   1882 sec\n",
      "[2020-03-19 09:14:48,668 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_1600.pt\n",
      "[2020-03-19 09:16:37,556 INFO] Step 1700/500000; acc:  56.93; ppl:  7.61; xent: 2.03; lr: 0.15000; 15165/1548 tok/s;   1992 sec\n",
      "[2020-03-19 09:18:21,317 INFO] Step 1800/500000; acc:  58.37; ppl:  7.30; xent: 1.99; lr: 0.15000; 15958/1530 tok/s;   2095 sec\n",
      "[2020-03-19 09:20:14,639 INFO] Step 1900/500000; acc:  60.79; ppl:  6.91; xent: 1.93; lr: 0.15000; 14273/1637 tok/s;   2209 sec\n",
      "[2020-03-19 09:21:58,830 INFO] Step 2000/500000; acc:  61.42; ppl:  6.46; xent: 1.87; lr: 0.15000; 15705/1579 tok/s;   2313 sec\n",
      "[2020-03-19 09:23:40,876 INFO] Step 2100/500000; acc:  59.90; ppl:  6.96; xent: 1.94; lr: 0.15000; 15441/1579 tok/s;   2415 sec\n",
      "[2020-03-19 09:25:24,084 INFO] Step 2200/500000; acc:  63.15; ppl:  5.93; xent: 1.78; lr: 0.15000; 16272/1462 tok/s;   2518 sec\n",
      "[2020-03-19 09:27:04,876 INFO] Step 2300/500000; acc:  65.52; ppl:  5.28; xent: 1.66; lr: 0.15000; 16722/1492 tok/s;   2619 sec\n",
      "[2020-03-19 09:28:54,087 INFO] Step 2400/500000; acc:  63.55; ppl:  5.83; xent: 1.76; lr: 0.15000; 15227/1490 tok/s;   2728 sec\n",
      "[2020-03-19 09:28:54,352 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_2400.pt\n",
      "[2020-03-19 09:30:44,513 INFO] Step 2500/500000; acc:  65.11; ppl:  5.32; xent: 1.67; lr: 0.15000; 14848/1488 tok/s;   2838 sec\n",
      "[2020-03-19 09:32:36,530 INFO] Step 2600/500000; acc:  65.44; ppl:  5.37; xent: 1.68; lr: 0.15000; 14943/1540 tok/s;   2950 sec\n",
      "[2020-03-19 09:34:26,000 INFO] Step 2700/500000; acc:  65.57; ppl:  5.43; xent: 1.69; lr: 0.15000; 15040/1560 tok/s;   3060 sec\n",
      "[2020-03-19 09:35:55,931 INFO] Step 2800/500000; acc:  65.50; ppl:  5.38; xent: 1.68; lr: 0.15000; 17799/1468 tok/s;   3150 sec\n",
      "[2020-03-19 09:37:45,640 INFO] Step 2900/500000; acc:  66.32; ppl:  5.26; xent: 1.66; lr: 0.15000; 15519/1516 tok/s;   3260 sec\n",
      "[2020-03-19 09:39:33,694 INFO] Step 3000/500000; acc:  68.64; ppl:  4.70; xent: 1.55; lr: 0.15000; 15858/1518 tok/s;   3368 sec\n",
      "[2020-03-19 09:41:17,267 INFO] Step 3100/500000; acc:  68.47; ppl:  4.65; xent: 1.54; lr: 0.15000; 16332/1422 tok/s;   3471 sec\n",
      "[2020-03-19 09:43:04,933 INFO] Step 3200/500000; acc:  69.68; ppl:  4.43; xent: 1.49; lr: 0.15000; 15377/1587 tok/s;   3579 sec\n",
      "[2020-03-19 09:43:05,217 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_3200.pt\n",
      "[2020-03-19 09:44:54,302 INFO] Step 3300/500000; acc:  67.12; ppl:  4.83; xent: 1.57; lr: 0.15000; 14819/1477 tok/s;   3688 sec\n",
      "[2020-03-19 09:46:30,673 INFO] Step 3400/500000; acc:  69.97; ppl:  4.36; xent: 1.47; lr: 0.15000; 17070/1520 tok/s;   3785 sec\n",
      "[2020-03-19 09:48:16,089 INFO] Step 3500/500000; acc:  65.94; ppl:  5.15; xent: 1.64; lr: 0.15000; 15340/1541 tok/s;   3890 sec\n",
      "[2020-03-19 09:50:05,457 INFO] Step 3600/500000; acc:  69.16; ppl:  4.65; xent: 1.54; lr: 0.15000; 15273/1596 tok/s;   3999 sec\n",
      "[2020-03-19 09:52:03,702 INFO] Step 3700/500000; acc:  67.63; ppl:  4.88; xent: 1.59; lr: 0.15000; 14352/1571 tok/s;   4118 sec\n",
      "[2020-03-19 09:53:52,778 INFO] Step 3800/500000; acc:  68.92; ppl:  4.52; xent: 1.51; lr: 0.15000; 15381/1558 tok/s;   4227 sec\n",
      "[2020-03-19 09:55:38,554 INFO] Step 3900/500000; acc:  68.83; ppl:  4.54; xent: 1.51; lr: 0.15000; 15646/1500 tok/s;   4333 sec\n",
      "[2020-03-19 09:57:31,923 INFO] Step 4000/500000; acc:  68.64; ppl:  4.62; xent: 1.53; lr: 0.15000; 14312/1578 tok/s;   4446 sec\n",
      "[2020-03-19 09:57:32,244 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_4000.pt\n",
      "[2020-03-19 09:59:23,399 INFO] Step 4100/500000; acc:  70.84; ppl:  4.14; xent: 1.42; lr: 0.15000; 14670/1412 tok/s;   4557 sec\n",
      "[2020-03-19 10:01:07,694 INFO] Step 4200/500000; acc:  70.23; ppl:  4.36; xent: 1.47; lr: 0.15000; 15310/1574 tok/s;   4662 sec\n",
      "[2020-03-19 10:02:48,688 INFO] Step 4300/500000; acc:  71.97; ppl:  3.99; xent: 1.38; lr: 0.15000; 16607/1510 tok/s;   4763 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-19 10:04:42,141 INFO] Step 4400/500000; acc:  67.33; ppl:  4.87; xent: 1.58; lr: 0.15000; 14293/1525 tok/s;   4876 sec\n",
      "[2020-03-19 10:06:36,639 INFO] Step 4500/500000; acc:  68.62; ppl:  4.62; xent: 1.53; lr: 0.15000; 14412/1612 tok/s;   4991 sec\n",
      "[2020-03-19 10:08:27,111 INFO] Step 4600/500000; acc:  70.34; ppl:  4.18; xent: 1.43; lr: 0.15000; 15355/1448 tok/s;   5101 sec\n",
      "[2020-03-19 10:10:16,809 INFO] Step 4700/500000; acc:  72.07; ppl:  3.90; xent: 1.36; lr: 0.15000; 15716/1548 tok/s;   5211 sec\n",
      "[2020-03-19 10:11:57,666 INFO] Step 4800/500000; acc:  69.65; ppl:  4.38; xent: 1.48; lr: 0.15000; 16006/1455 tok/s;   5312 sec\n",
      "[2020-03-19 10:11:57,987 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_4800.pt\n",
      "[2020-03-19 10:13:36,107 INFO] Step 4900/500000; acc:  70.47; ppl:  4.14; xent: 1.42; lr: 0.15000; 16573/1480 tok/s;   5410 sec\n",
      "[2020-03-19 10:15:27,444 INFO] Step 5000/500000; acc:  71.26; ppl:  4.04; xent: 1.40; lr: 0.15000; 15081/1578 tok/s;   5521 sec\n",
      "[2020-03-19 10:17:22,333 INFO] Step 5100/500000; acc:  72.60; ppl:  3.84; xent: 1.35; lr: 0.15000; 14598/1532 tok/s;   5636 sec\n",
      "[2020-03-19 10:19:11,586 INFO] Step 5200/500000; acc:  71.61; ppl:  4.05; xent: 1.40; lr: 0.15000; 14930/1532 tok/s;   5746 sec\n",
      "[2020-03-19 10:20:50,225 INFO] Step 5300/500000; acc:  72.74; ppl:  3.78; xent: 1.33; lr: 0.15000; 16488/1531 tok/s;   5844 sec\n",
      "[2020-03-19 10:22:35,828 INFO] Step 5400/500000; acc:  73.46; ppl:  3.70; xent: 1.31; lr: 0.15000; 15996/1503 tok/s;   5950 sec\n",
      "[2020-03-19 10:24:29,110 INFO] Step 5500/500000; acc:  72.30; ppl:  3.86; xent: 1.35; lr: 0.15000; 14520/1579 tok/s;   6063 sec\n",
      "[2020-03-19 10:26:14,880 INFO] Step 5600/500000; acc:  71.45; ppl:  3.98; xent: 1.38; lr: 0.15000; 15776/1540 tok/s;   6169 sec\n",
      "[2020-03-19 10:26:15,234 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_5600.pt\n",
      "[2020-03-19 10:27:51,633 INFO] Step 5700/500000; acc:  71.98; ppl:  3.81; xent: 1.34; lr: 0.15000; 17243/1384 tok/s;   6266 sec\n",
      "[2020-03-19 10:29:39,469 INFO] Step 5800/500000; acc:  71.17; ppl:  4.02; xent: 1.39; lr: 0.15000; 15126/1580 tok/s;   6373 sec\n",
      "[2020-03-19 10:31:34,243 INFO] Step 5900/500000; acc:  70.80; ppl:  4.12; xent: 1.42; lr: 0.15000; 14238/1569 tok/s;   6488 sec\n",
      "[2020-03-19 10:33:22,170 INFO] Step 6000/500000; acc:  72.64; ppl:  3.75; xent: 1.32; lr: 0.15000; 15660/1387 tok/s;   6596 sec\n",
      "[2020-03-19 10:35:16,521 INFO] Step 6100/500000; acc:  70.99; ppl:  4.04; xent: 1.40; lr: 0.15000; 14741/1498 tok/s;   6710 sec\n",
      "[2020-03-19 10:37:04,345 INFO] Step 6200/500000; acc:  70.35; ppl:  4.12; xent: 1.42; lr: 0.15000; 14992/1571 tok/s;   6818 sec\n",
      "[2020-03-19 10:38:43,766 INFO] Step 6300/500000; acc:  73.71; ppl:  3.52; xent: 1.26; lr: 0.15000; 16818/1397 tok/s;   6918 sec\n",
      "[2020-03-19 10:40:30,239 INFO] Step 6400/500000; acc:  72.03; ppl:  3.88; xent: 1.36; lr: 0.15000; 15318/1502 tok/s;   7024 sec\n",
      "[2020-03-19 10:40:30,586 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_6400.pt\n",
      "[2020-03-19 10:42:18,616 INFO] Step 6500/500000; acc:  73.40; ppl:  3.61; xent: 1.28; lr: 0.15000; 15320/1570 tok/s;   7133 sec\n",
      "[2020-03-19 10:44:06,290 INFO] Step 6600/500000; acc:  72.21; ppl:  3.84; xent: 1.34; lr: 0.15000; 15316/1458 tok/s;   7240 sec\n",
      "[2020-03-19 10:45:54,469 INFO] Step 6700/500000; acc:  74.01; ppl:  3.51; xent: 1.26; lr: 0.15000; 15519/1490 tok/s;   7348 sec\n",
      "[2020-03-19 10:47:51,139 INFO] Step 6800/500000; acc:  73.21; ppl:  3.72; xent: 1.31; lr: 0.15000; 14483/1541 tok/s;   7465 sec\n",
      "[2020-03-19 10:49:41,306 INFO] Step 6900/500000; acc:  72.46; ppl:  3.76; xent: 1.33; lr: 0.15000; 14944/1503 tok/s;   7575 sec\n",
      "[2020-03-19 10:51:24,484 INFO] Step 7000/500000; acc:  74.36; ppl:  3.44; xent: 1.24; lr: 0.15000; 16304/1455 tok/s;   7678 sec\n",
      "[2020-03-19 10:53:11,245 INFO] Step 7100/500000; acc:  72.14; ppl:  3.84; xent: 1.35; lr: 0.15000; 15541/1481 tok/s;   7785 sec\n",
      "[2020-03-19 10:54:56,160 INFO] Step 7200/500000; acc:  74.23; ppl:  3.50; xent: 1.25; lr: 0.15000; 15636/1550 tok/s;   7890 sec\n",
      "[2020-03-19 10:54:56,514 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_7200.pt\n",
      "[2020-03-19 10:56:31,059 INFO] Step 7300/500000; acc:  74.89; ppl:  3.32; xent: 1.20; lr: 0.15000; 17574/1459 tok/s;   7985 sec\n",
      "[2020-03-19 10:58:22,566 INFO] Step 7400/500000; acc:  73.41; ppl:  3.57; xent: 1.27; lr: 0.15000; 15087/1514 tok/s;   8097 sec\n",
      "[2020-03-19 11:00:07,270 INFO] Step 7500/500000; acc:  72.54; ppl:  3.77; xent: 1.33; lr: 0.15000; 15675/1537 tok/s;   8201 sec\n",
      "[2020-03-19 11:02:00,892 INFO] Step 7600/500000; acc:  72.84; ppl:  3.67; xent: 1.30; lr: 0.15000; 14817/1571 tok/s;   8315 sec\n",
      "[2020-03-19 11:03:56,560 INFO] Step 7700/500000; acc:  72.45; ppl:  3.72; xent: 1.31; lr: 0.15000; 14359/1502 tok/s;   8431 sec\n",
      "[2020-03-19 11:05:46,144 INFO] Step 7800/500000; acc:  71.56; ppl:  3.90; xent: 1.36; lr: 0.15000; 14627/1618 tok/s;   8540 sec\n",
      "[2020-03-19 11:07:32,569 INFO] Step 7900/500000; acc:  74.38; ppl:  3.40; xent: 1.22; lr: 0.15000; 15416/1462 tok/s;   8647 sec\n",
      "[2020-03-19 11:09:07,964 INFO] Step 8000/500000; acc:  74.00; ppl:  3.44; xent: 1.23; lr: 0.15000; 16802/1522 tok/s;   8742 sec\n",
      "[2020-03-19 11:09:08,334 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_8000.pt\n",
      "[2020-03-19 11:10:58,411 INFO] Step 8100/500000; acc:  74.61; ppl:  3.37; xent: 1.22; lr: 0.15000; 15127/1429 tok/s;   8852 sec\n",
      "[2020-03-19 11:12:59,744 INFO] Step 8200/500000; acc:  73.61; ppl:  3.61; xent: 1.28; lr: 0.15000; 13573/1485 tok/s;   8974 sec\n",
      "[2020-03-19 11:15:03,931 INFO] Step 8300/500000; acc:  75.18; ppl:  3.36; xent: 1.21; lr: 0.15000; 13533/1533 tok/s;   9098 sec\n",
      "[2020-03-19 11:16:56,191 INFO] Step 8400/500000; acc:  74.14; ppl:  3.47; xent: 1.24; lr: 0.15000; 14423/1296 tok/s;   9210 sec\n",
      "[2020-03-19 11:18:40,302 INFO] Step 8500/500000; acc:  74.53; ppl:  3.42; xent: 1.23; lr: 0.15000; 15828/1404 tok/s;   9314 sec\n",
      "[2020-03-19 11:20:44,669 INFO] Step 8600/500000; acc:  74.31; ppl:  3.39; xent: 1.22; lr: 0.15000; 13696/1264 tok/s;   9439 sec\n",
      "[2020-03-19 11:22:40,603 INFO] Step 8700/500000; acc:  75.89; ppl:  3.21; xent: 1.17; lr: 0.15000; 14447/1461 tok/s;   9555 sec\n",
      "[2020-03-19 11:24:36,933 INFO] Step 8800/500000; acc:  73.93; ppl:  3.49; xent: 1.25; lr: 0.15000; 14257/1375 tok/s;   9671 sec\n",
      "[2020-03-19 11:24:37,350 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_8800.pt\n",
      "[2020-03-19 11:26:32,467 INFO] Step 8900/500000; acc:  73.60; ppl:  3.57; xent: 1.27; lr: 0.15000; 13936/1364 tok/s;   9786 sec\n",
      "[2020-03-19 11:28:31,405 INFO] Step 9000/500000; acc:  75.83; ppl:  3.21; xent: 1.17; lr: 0.15000; 14171/1392 tok/s;   9905 sec\n",
      "[2020-03-19 11:30:29,647 INFO] Step 9100/500000; acc:  74.06; ppl:  3.43; xent: 1.23; lr: 0.15000; 14061/1366 tok/s;  10024 sec\n",
      "[2020-03-19 11:32:31,589 INFO] Step 9200/500000; acc:  75.19; ppl:  3.28; xent: 1.19; lr: 0.15000; 13810/1497 tok/s;  10146 sec\n",
      "[2020-03-19 11:34:31,577 INFO] Step 9300/500000; acc:  76.21; ppl:  3.21; xent: 1.17; lr: 0.15000; 13763/1490 tok/s;  10266 sec\n",
      "[2020-03-19 11:36:29,630 INFO] Step 9400/500000; acc:  75.11; ppl:  3.31; xent: 1.20; lr: 0.15000; 14009/1369 tok/s;  10384 sec\n",
      "[2020-03-19 11:38:29,654 INFO] Step 9500/500000; acc:  74.72; ppl:  3.31; xent: 1.20; lr: 0.15000; 14137/1420 tok/s;  10504 sec\n",
      "[2020-03-19 11:40:22,987 INFO] Step 9600/500000; acc:  74.46; ppl:  3.37; xent: 1.22; lr: 0.15000; 14792/1332 tok/s;  10617 sec\n",
      "[2020-03-19 11:40:23,378 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_9600.pt\n",
      "[2020-03-19 11:42:15,312 INFO] Step 9700/500000; acc:  74.90; ppl:  3.33; xent: 1.20; lr: 0.15000; 14655/1405 tok/s;  10729 sec\n",
      "[2020-03-19 11:44:03,560 INFO] Step 9800/500000; acc:  73.79; ppl:  3.45; xent: 1.24; lr: 0.15000; 14689/1373 tok/s;  10838 sec\n",
      "[2020-03-19 11:46:05,189 INFO] Step 9900/500000; acc:  74.21; ppl:  3.40; xent: 1.22; lr: 0.15000; 13436/1408 tok/s;  10959 sec\n",
      "[2020-03-19 11:48:02,845 INFO] Step 10000/500000; acc:  74.98; ppl:  3.35; xent: 1.21; lr: 0.15000; 13893/1458 tok/s;  11077 sec\n",
      "[2020-03-19 11:49:52,885 INFO] Step 10100/500000; acc:  75.35; ppl:  3.24; xent: 1.18; lr: 0.15000; 14671/1385 tok/s;  11187 sec\n",
      "[2020-03-19 11:52:00,733 INFO] Step 10200/500000; acc:  74.97; ppl:  3.27; xent: 1.18; lr: 0.15000; 13358/1315 tok/s;  11315 sec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2020-03-19 11:53:59,393 INFO] Step 10300/500000; acc:  75.12; ppl:  3.25; xent: 1.18; lr: 0.15000; 14298/1362 tok/s;  11433 sec\n",
      "[2020-03-19 11:56:02,234 INFO] Step 10400/500000; acc:  73.88; ppl:  3.48; xent: 1.25; lr: 0.15000; 13520/1429 tok/s;  11556 sec\n",
      "[2020-03-19 11:56:02,642 INFO] Saving checkpoint models/cc/pretrained_model_benchmark_step_10400.pt\n",
      "[2020-03-19 11:58:07,715 INFO] Step 10500/500000; acc:  73.90; ppl:  3.52; xent: 1.26; lr: 0.15000; 12788/1476 tok/s;  11682 sec\n",
      "[2020-03-19 12:00:10,592 INFO] Step 10600/500000; acc:  75.84; ppl:  3.22; xent: 1.17; lr: 0.15000; 13843/1421 tok/s;  11805 sec\n",
      "[2020-03-19 12:02:09,138 INFO] Step 10700/500000; acc:  74.55; ppl:  3.36; xent: 1.21; lr: 0.15000; 13883/1332 tok/s;  11923 sec\n",
      "[2020-03-19 12:04:04,492 INFO] Step 10800/500000; acc:  75.61; ppl:  3.18; xent: 1.16; lr: 0.15000; 14489/1385 tok/s;  12038 sec\n"
     ]
    }
   ],
   "source": [
    "!onmt_train -data data/cc/pretrain_data \\\n",
    "            -save_model models/cc/pretrained_model_benchmark \\\n",
    "            -batch_size 60 \\\n",
    "            -report_every 200 \\\n",
    "            -world_size 1 \\\n",
    "            -gpu_ranks 0 \\\n",
    "            -copy_attn -global_attention mlp \\\n",
    "            -word_vec_size 128 \\\n",
    "            -rnn_size 512 \\\n",
    "            -layers 1 \\\n",
    "            -encoder_type brnn \\\n",
    "            -train_steps 500000 \\\n",
    "            -max_grad_norm 2 \\\n",
    "            -dropout 0. \\\n",
    "            -optim adagrad \\\n",
    "            -learning_rate 0.15 \\\n",
    "            -adagrad_accumulator_init 0.1 \\\n",
    "            -reuse_copy_attn \\\n",
    "            -copy_loss_by_seqlength\\\n",
    "            -bridge \\\n",
    "            -seed 777 \\\n",
    "            -save_checkpoint_steps 800 \\\n",
    "            -keep_checkpoint 400\n",
    "            #-log_file log/cc/log_cc_new_pointer_gen.txt \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "677957\n"
     ]
    }
   ],
   "source": [
    "# a = open('raw_data/cc/pretrain-tgt-train.txt','r',  encoding = 'utf-8').readlines()\n",
    "# print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openNMT-py\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/1c/48faee4ea981aa96292d03cfd5a43f415ae03309db9ab4f625dd4aa6dc71/OpenNMT_py-1.0.2-py3-none-any.whl (183kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 3.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting future\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
      "\u001b[K     |████████████████████████████████| 829kB 10.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm~=4.30.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/4c/103a4d3415dafc1ddfe6a6624333971756e2d3dd8c6dc0f520152855f040/tqdm-4.30.0-py2.py3-none-any.whl (47kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 10.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting torch>=1.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/19/4804aea17cd136f1705a5e98a00618cb8f6ccc375ad8bfa437408e09d058/torch-1.4.0-cp36-cp36m-manylinux1_x86_64.whl (753.4MB)\n",
      "\u001b[K     |████████████████████████████████| 753.4MB 11kB/s s eta 0:00:01     |██████▌                         | 153.3MB 51.7MB/s eta 0:00:12     |████████▋                       | 203.2MB 54.9MB/s eta 0:00:11     |████████████████▉               | 395.3MB 52.6MB/s eta 0:00:07     |██████████████████████████████▍ | 715.7MB 65.2MB/s eta 0:00:01     |███████████████████████████████▋| 745.2MB 65.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting waitress\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/ca/ede3ed29723ca944f6e77bd1d7b38c271dd801c7d6a11ab6037597e4fd5b/waitress-1.4.3-py2.py3-none-any.whl (148kB)\n",
      "\u001b[K     |████████████████████████████████| 153kB 32.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from openNMT-py) (1.11.0)\n",
      "Collecting configargparse\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/9a/05a375c2e34992c6eb8bda11a545f65116935c30d2d7bef2bb9e606b12eb/ConfigArgParse-1.1.tar.gz (41kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 9.6MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting torchtext==0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
      "\u001b[K     |████████████████████████████████| 61kB 10.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyonmttok==1.*; platform_system == \"Linux\"\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/20/3c57198ffe690b580fbf23d33d5000eb411862e60e4bb6853b61dc989187/pyonmttok-1.18.3-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2MB 25.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tensorboard>=1.14 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from openNMT-py) (1.15.0)\n",
      "Requirement already satisfied: flask in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from openNMT-py) (1.0.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from torchtext==0.4.0->openNMT-py) (2.20.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from torchtext==0.4.0->openNMT-py) (1.16.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard>=1.14->openNMT-py) (3.8.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard>=1.14->openNMT-py) (0.9.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard>=1.14->openNMT-py) (3.2.1)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard>=1.14->openNMT-py) (0.31.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard>=1.14->openNMT-py) (0.14.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard>=1.14->openNMT-py) (45.2.0)\n",
      "Requirement already satisfied: grpcio>=1.6.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from tensorboard>=1.14->openNMT-py) (1.10.1)\n",
      "Requirement already satisfied: click>=5.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from flask->openNMT-py) (6.7)\n",
      "Requirement already satisfied: Jinja2>=2.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from flask->openNMT-py) (2.10)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from flask->openNMT-py) (0.24)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0->openNMT-py) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0->openNMT-py) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0->openNMT-py) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from requests->torchtext==0.4.0->openNMT-py) (1.23)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from Jinja2>=2.10->flask->openNMT-py) (1.0)\n",
      "Building wheels for collected packages: future, configargparse\n",
      "  Building wheel for future (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for future: filename=future-0.18.2-cp36-none-any.whl size=491095 sha256=fa16a1e26cee7e2ea3361f7b7f5c8fc073de6ad7659dad731de27a0d3573ce3a\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
      "  Building wheel for configargparse (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for configargparse: filename=ConfigArgParse-1.1-cp36-none-any.whl size=17644 sha256=e29a5e2f400b023db8385c5b5dc343db6120e399ebf3f6122a3153644af4d2f9\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c7/7e/f4/c06c06885801afada0eed24872e363d11bacde7c3a1aaacbb9\n",
      "Successfully built future configargparse\n",
      "Installing collected packages: future, tqdm, torch, waitress, configargparse, torchtext, pyonmttok, openNMT-py\n",
      "Successfully installed configargparse-1.1 future-0.18.2 openNMT-py-1.0.2 pyonmttok-1.18.3 torch-1.4.0 torchtext-0.4.0 tqdm-4.30.0 waitress-1.4.3\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip  install openNMT-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: onmt_train [-h] [-config CONFIG] [-save_config SAVE_CONFIG]\r\n",
      "                  [--src_word_vec_size SRC_WORD_VEC_SIZE]\r\n",
      "                  [--tgt_word_vec_size TGT_WORD_VEC_SIZE]\r\n",
      "                  [--word_vec_size WORD_VEC_SIZE] [--share_decoder_embeddings]\r\n",
      "                  [--share_embeddings] [--position_encoding]\r\n",
      "                  [--feat_merge {concat,sum,mlp}]\r\n",
      "                  [--feat_vec_size FEAT_VEC_SIZE]\r\n",
      "                  [--feat_vec_exponent FEAT_VEC_EXPONENT]\r\n",
      "                  [--model_type {text,img,audio,vec}]\r\n",
      "                  [--model_dtype {fp32,fp16}]\r\n",
      "                  [--encoder_type {rnn,brnn,mean,transformer,cnn}]\r\n",
      "                  [--decoder_type {rnn,transformer,cnn}] [--layers LAYERS]\r\n",
      "                  [--enc_layers ENC_LAYERS] [--dec_layers DEC_LAYERS]\r\n",
      "                  [--rnn_size RNN_SIZE] [--enc_rnn_size ENC_RNN_SIZE]\r\n",
      "                  [--dec_rnn_size DEC_RNN_SIZE]\r\n",
      "                  [--audio_enc_pooling AUDIO_ENC_POOLING]\r\n",
      "                  [--cnn_kernel_width CNN_KERNEL_WIDTH]\r\n",
      "                  [--input_feed INPUT_FEED] [--bridge]\r\n",
      "                  [--rnn_type {LSTM,GRU,SRU}] [--brnn]\r\n",
      "                  [--context_gate {source,target,both}]\r\n",
      "                  [--global_attention {dot,general,mlp,none}]\r\n",
      "                  [--global_attention_function {softmax,sparsemax}]\r\n",
      "                  [--self_attn_type SELF_ATTN_TYPE]\r\n",
      "                  [--max_relative_positions MAX_RELATIVE_POSITIONS]\r\n",
      "                  [--heads HEADS] [--transformer_ff TRANSFORMER_FF]\r\n",
      "                  [--aan_useffn] [--lambda_align LAMBDA_ALIGN]\r\n",
      "                  [--alignment_layer ALIGNMENT_LAYER]\r\n",
      "                  [--alignment_heads ALIGNMENT_HEADS]\r\n",
      "                  [--full_context_alignment] [--copy_attn]\r\n",
      "                  [--copy_attn_type {dot,general,mlp,none}]\r\n",
      "                  [--generator_function {softmax,sparsemax}]\r\n",
      "                  [--copy_attn_force] [--reuse_copy_attn]\r\n",
      "                  [--copy_loss_by_seqlength] [--coverage_attn]\r\n",
      "                  [--lambda_coverage LAMBDA_COVERAGE]\r\n",
      "                  [--loss_scale LOSS_SCALE] [--apex_opt_level {O0,O1,O2,O3}]\r\n",
      "                  --data DATA [--data_ids DATA_IDS [DATA_IDS ...]]\r\n",
      "                  [--data_weights DATA_WEIGHTS [DATA_WEIGHTS ...]]\r\n",
      "                  [--save_model SAVE_MODEL]\r\n",
      "                  [--save_checkpoint_steps SAVE_CHECKPOINT_STEPS]\r\n",
      "                  [--keep_checkpoint KEEP_CHECKPOINT]\r\n",
      "                  [--gpuid [GPUID [GPUID ...]]]\r\n",
      "                  [--gpu_ranks [GPU_RANKS [GPU_RANKS ...]]]\r\n",
      "                  [--world_size WORLD_SIZE] [--gpu_backend GPU_BACKEND]\r\n",
      "                  [--gpu_verbose_level GPU_VERBOSE_LEVEL]\r\n",
      "                  [--master_ip MASTER_IP] [--master_port MASTER_PORT]\r\n",
      "                  [--queue_size QUEUE_SIZE] [--seed SEED]\r\n",
      "                  [--param_init PARAM_INIT] [--param_init_glorot]\r\n",
      "                  [--train_from TRAIN_FROM]\r\n",
      "                  [--reset_optim {none,all,states,keep_states}]\r\n",
      "                  [--pre_word_vecs_enc PRE_WORD_VECS_ENC]\r\n",
      "                  [--pre_word_vecs_dec PRE_WORD_VECS_DEC]\r\n",
      "                  [--fix_word_vecs_enc] [--fix_word_vecs_dec]\r\n",
      "                  [--batch_size BATCH_SIZE] [--batch_type {sents,tokens}]\r\n",
      "                  [--pool_factor POOL_FACTOR] [--normalization {sents,tokens}]\r\n",
      "                  [--accum_count ACCUM_COUNT [ACCUM_COUNT ...]]\r\n",
      "                  [--accum_steps ACCUM_STEPS [ACCUM_STEPS ...]]\r\n",
      "                  [--valid_steps VALID_STEPS]\r\n",
      "                  [--valid_batch_size VALID_BATCH_SIZE]\r\n",
      "                  [--max_generator_batches MAX_GENERATOR_BATCHES]\r\n",
      "                  [--train_steps TRAIN_STEPS] [--single_pass]\r\n",
      "                  [--epochs EPOCHS] [--early_stopping EARLY_STOPPING]\r\n",
      "                  [--early_stopping_criteria [EARLY_STOPPING_CRITERIA [EARLY_STOPPING_CRITERIA ...]]]\r\n",
      "                  [--optim {sgd,adagrad,adadelta,adam,sparseadam,adafactor,fusedadam}]\r\n",
      "                  [--adagrad_accumulator_init ADAGRAD_ACCUMULATOR_INIT]\r\n",
      "                  [--max_grad_norm MAX_GRAD_NORM]\r\n",
      "                  [--dropout DROPOUT [DROPOUT ...]]\r\n",
      "                  [--attention_dropout ATTENTION_DROPOUT [ATTENTION_DROPOUT ...]]\r\n",
      "                  [--dropout_steps DROPOUT_STEPS [DROPOUT_STEPS ...]]\r\n",
      "                  [--truncated_decoder TRUNCATED_DECODER]\r\n",
      "                  [--adam_beta1 ADAM_BETA1] [--adam_beta2 ADAM_BETA2]\r\n",
      "                  [--label_smoothing LABEL_SMOOTHING]\r\n",
      "                  [--average_decay AVERAGE_DECAY]\r\n",
      "                  [--average_every AVERAGE_EVERY]\r\n",
      "                  [--learning_rate LEARNING_RATE]\r\n",
      "                  [--learning_rate_decay LEARNING_RATE_DECAY]\r\n",
      "                  [--start_decay_steps START_DECAY_STEPS]\r\n",
      "                  [--decay_steps DECAY_STEPS]\r\n",
      "                  [--decay_method {noam,noamwd,rsqrt,none}]\r\n",
      "                  [--warmup_steps WARMUP_STEPS] [--report_every REPORT_EVERY]\r\n",
      "                  [--log_file LOG_FILE]\r\n",
      "                  [--log_file_level {CRITICAL,ERROR,WARNING,INFO,DEBUG,NOTSET,50,40,30,20,10,0}]\r\n",
      "                  [--exp_host EXP_HOST] [--exp EXP] [--tensorboard]\r\n",
      "                  [--tensorboard_log_dir TENSORBOARD_LOG_DIR]\r\n",
      "                  [--sample_rate SAMPLE_RATE] [--window_size WINDOW_SIZE]\r\n",
      "                  [--image_channel_size {3,1}]\r\n",
      "onmt_train: error: the following arguments are required: --data/-data\r\n"
     ]
    }
   ],
   "source": [
    "#!onmt_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
